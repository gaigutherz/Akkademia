from akkadian.data import logits_to_trans, load_object_from_file
from akkadian.combine_algorithms import overall_classifier, list_to_tran, sentence_to_allen_format, sentence_to_HMM_format
from akkadian.hmm import hmm_viterbi
from akkadian.memm import memm_greedy
from akkadian.__init__ import hmm_path, memm_path, bilstm_path


def sanitize(sentence):
    out_sentence = ""
    for sign in sentence:
        if 0x12000 <= ord(sign) or ord(sign) == 'x':
            out_sentence += sign

    return out_sentence


def transliterate(sentence):
    """
    Transliterate signs using best transliteration algorithm so far
    :param sentence: signs to be transliterated
    :return: transliteration of the sentence
    """
    return transliterate_bilstm(sentence)


def transliterate_bilstm(sentence):
    """
    Transliterate signs using biLSTM
    :param sentence: signs to be transliterated
    :return: transliteration of the sentence
    """
    sentence = sanitize(sentence)

    model, predictor, sign_to_id, id_to_tran, test_texts = load_object_from_file(bilstm_path)

    tag_logits = predictor.predict(sentence_to_allen_format(sentence, sign_to_id, True))['tag_logits']
    biLSTM_predicted_tags, _, _, _, _, _ = logits_to_trans(tag_logits, model, id_to_tran)
    return list_to_tran(biLSTM_predicted_tags)


def transliterate_bilstm_top3(sentence):
    """
    Transliterate signs using biLSTM
    :param sentence: signs to be transliterated
    :return: 3 top transliterations of the sentence with their scores
    """
    sentence = sanitize(sentence)

    model, predictor, sign_to_id, id_to_tran, test_texts = load_object_from_file(bilstm_path)

    tag_logits = predictor.predict(sentence_to_allen_format(sentence, sign_to_id, True))['tag_logits']
    prediction1, prediction2, prediction3, score1, score2, score3 = logits_to_trans(tag_logits, model, id_to_tran)
    return list_to_tran(prediction1), list_to_tran(prediction2), list_to_tran(prediction3)


def transliterate_hmm(sentence):
    """
    Transliterate signs using HMM
    :param sentence: signs to be transliterated
    :return: transliteration of the sentence
    """
    sentences = [sanitize(line) for line in sentence.splitlines() if len(sanitize(line)) > 0]

    most_common_tag, possible_tags, q, e, S, total_tokens, q_bi_counts, q_uni_counts, lambda1, lambda2, test_texts = \
        load_object_from_file(hmm_path)

    HMM_predicted_tags_list = [hmm_viterbi(sentence_to_HMM_format(s), total_tokens, q_bi_counts, q_uni_counts, q, e,
                           S, most_common_tag, possible_tags, lambda1, lambda2) for s in sentences]
    tran_list = [list_to_tran(HMM_predicted_tags) for HMM_predicted_tags in HMM_predicted_tags_list]

    return ''.join(tran_list)


def transliterate_memm(sentence):
    """
    Transliterate signs using MEMM
    :param sentence: signs to be transliterated
    :return: transliteration of the sentence
    """
    sentences = [sanitize(line) for line in sentence.splitlines() if len(sanitize(line)) > 0]

    logreg, vec, idx_to_tag_dict, test_texts = load_object_from_file(memm_path)

    MEMM_predicted_tags_list = [memm_greedy(sentence_to_HMM_format(s), logreg, vec, idx_to_tag_dict) for s in sentences]
    tran_list = [list_to_tran(MEMM_predicted_tags) for MEMM_predicted_tags in MEMM_predicted_tags_list]

    return ''.join(tran_list)


def main():
    """
    Loads all models' learned data and open an interpreter for transliterating sentences of signs from input
    :return: nothing, never stops
    """
    most_common_tag, possible_tags, q, e, S, total_tokens, q_bi_counts, q_uni_counts, lambda1, lambda2, test_texts = \
        load_object_from_file(hmm_path)

    logreg, vec, idx_to_tag_dict, test_texts = load_object_from_file(memm_path)

    model, predictor, sign_to_id, id_to_tran, test_texts = load_object_from_file(bilstm_path)

    gamma1 = 0.4
    gamma2 = 0.2

    """
    Sennacherib = "ğ’¹ğ’€­ğ’Œğ’‹€ğ’ˆ¨ğ’Œğ’Œ·ğ’€"
    """

    while True:
        sentence = input("write here:")

        if sentence == "":
            continue

        overall_classifier(sentence, gamma1, gamma2, total_tokens, q_bi_counts, q_uni_counts,
            q, e, S, most_common_tag, possible_tags, lambda1, lambda2, logreg, vec, idx_to_tag_dict, predictor, model,
                                                    id_to_tran, sign_to_id, True)


if __name__ == '__main__':
    # main()
    example = """
1	
ğ’¹ğ’€­ğ’‹¾ğ’€ªğ’†ªğ’Š» ğ’ˆ— ğ’ƒ²ğ’Œ‘

 	
ğ’ˆ— ğ’†—ğ’‰¡ ğ’ˆ— ğ’Š¹ ğ’ˆ— ğ’‚Šğ’†  ğ’ˆ— ğ’†³ğ’†³

 	
ğ’ğ’‰Œğ’…” ğ’‚ğ’Š•ğ’… ğ’…‡ ğ’‚ğ’£ğ’•

 	
ğ’Œ‰ğ’‘ ğ’Š•ğ’†— ğ’Š­ ğ’¹ğ’‹›ğ’‡»ğ’ŠŒğ’†ª ğ’ˆ—

5	
ğ’‡½ğ’ˆ ğ’€ğ’…—ğ’ºğ’ˆ¾ğ’€€ğ’€€ ğ’ˆ— ğ’‚Šğ’† 

 	
ğ’€€ğ’ˆ¾ğ’†ª ğ’„¿ğ’‰¡ğ’ˆ  ğ’€€ğ’ˆ¾ ğ’‚Šğ’‰ğ’…–

 	
ğ’‚ğ’Š•ğ’… ğ’…‡ ğ’‚ğ’£ğ’•

 	
ğ’Š®ğ’‰ ğ’Œ’ğ’‡´ğ’ˆ  ğ’‹ğ’„­ğ’€€

 	
ğ’‚ğ’Š•ğ’… ğ’…‡ ğ’‚ğ’£ğ’•

10
ğ’€¸ ğ’†³ğ’„©ğ’€œğ’´ ğ’€¸ ğ’‹—ğ’ˆ«ğ’Š ğ’‚–ğ’‡·ğ’‹¾

 	
ğ’„¿ğ’ˆ¾ ğ’‰Œğ’„‘ ğ’Š’ğ’‘ğ’‹¾ ğ’€ ğ’‰ğ’…”ğ’ˆ 

 	
ğ’€€ğ’ˆ¾ ğ’ˆ¾ğ’²ğ’‚Š ğ’‘ğ’‹— ğ’Š­ ğ’‚ğ’Š•ğ’…

 	
ğ’…‡ ğ’‚ğ’£ğ’• ğ’Œ’ğ’‰ğ’…‹ ğ’€¸ ğ’Œ—ğ’Šº ğ’Œ“ğ’Œ‹ğ’Œ‹ğ’„°

 	
ğ’ˆ¬ğ’ğ’ˆğ’„° ğ’‘ğ’‹— ğ’Š­ ğ’‚ğ’£ğ’•

15	
ğ’‚ ğ’† ğ’„¿ğ’‰Œ ğ’‚ ğ’€­ğ’€ ğ’ƒ» ğ’† ğ’†— ğ’‡ğ’¦ğ’† 

 	
ğ’€œğ’²ğ’‚Š ğ’‘ğ’…†ğ’‹— ğ’€­ğ’€ ğ’Œ‰ğ’‘ ğ’¢ğ’„¿ğ’Š‘

 	
ğ’…†ğ’……ğ’†· ğ’€­ğ’ˆ¨ğ’Œ ğ’ˆ²ğ’‹»ğ’„·

 	
ğ’Š­ ğ’€€ğ’ˆ¾ ğ’‹«ğ’ˆ¾ğ’•ğ’€€ğ’‹¾

 	
ğ’‹ƒğ’†ªğ’‰¡ ğ’Œ‰ğ’‘ ğ’Š•ğ’Œ…ğ’Œ‘

20	
ğ’Š­ ğ’€­ğ’€«ğ’Œ“ ğ’„¿ğ’€–ğ’‹¾ ğ’€­ğ’€€ğ’‚”ğ’Œ‘ğ’€€

 	
ğ’Š¬ğ’‹¥ ğ’‰ºğ’‹¾ğ’‹—ğ’ˆ« ğ’€®ğ’‰Œğ’‹¾

 	
ğ’„©ğ’¹ ğ’€®ğ’‡·ğ’„‘ğ’ˆ 

 	
ğ’„¿ğ’ˆ¾ ğ’† ğ’‰ğ’‹¾ğ’…— ğ’¢ğ’…•ğ’‹¾

 	
ğ’Š­ ğ’†· ğ’…”ğ’Š©ğ’Œ†ğ’‰¡ğ’Œ‘ ğ’† ğ’‚ğ’‹¢

25	
ğ’‹—ğ’Œğ’„£ğ’Œ“ ğ’ˆ ğ’€€ğ’‹¾ ğ’€€ğ’€€ğ’‰ğ’Š

 	
ğ’…—ğ’ƒ»ğ’º ğ’…•ğ’‰Œğ’€‰ğ’‹¾ğ’Š

 	
ğ’Œ‹ğ’…— ğ’ˆ¾ğ’† ğ’Š‘ ğ’Œ‘ğ’‹—ğ’Š»ğ’ª ğ’„¿ğ’ˆ¾ ğ’‡·ğ’„¿ğ’‹¾

 	
ğ’ˆ—ğ’Œ‘ğ’Œ… ğ’ˆªğ’ƒ»ğ’Š‘ ğ’‰ºğ’‡·ğ’‚Š

 	
ğ’ğ’€€ğ’Š‘ ğ’ˆ¬ğ’€­ğ’ˆ¾ğ’ˆ¨ğ’Œ ğ’‚…ğ’Œ’ ğ’Š®ğ’‰

30	
ğ’Šºğ’‰ğ’‚Š ğ’€–ğ’Œ…ğ’Œ… ğ’‡» ğ’…†ğ’Š‘ğ’……ğ’‹¾

 	
ğ’ˆ—ğ’Œ‘ğ’‹¾ ğ’ƒ» ğ’¹ğ’€­ğ’‹¾ğ’€ªğ’†ªğ’Š»

 	
ğ’…‡ ğ’‹›ğ’‡»ğ’ŠŒğ’†ª ğ’ˆ— ğ’Œ‰ğ’‹™

 	
ğ’€€ğ’ˆ¾ ğ’•ğ’Šğ’€€ğ’‹¾ ğ’Œ‰ ğ’Š’ğ’‰ğ’‚Š

 	
ğ’€­ğ’€ ğ’Œ‰ğ’‘ ğ’‚ğ’Š•ğ’…

35	
ğ’ğ’‰½ ğ’€­ğ’‚ğ’Š‘ ğ’Š•ğ’Œ…ğ’Œ‘

 	
ğ’„¿ğ’€–ğ’‹¾ ğ’€­ğ’€€ğ’‚”ğ’Œ‘ğ’€€ ğ’Š¬ğ’‹¥

 	
ğ’€€ğ’ˆ¾ ğ’‚ğ’£ğ’• ğ’‚ ğ’† ğ’„¿ğ’‰Œ

 	
ğ’‚ ğ’€­ğ’€€ğ’‰¡ğ’‹¾ğ’…— ğ’‹—ğ’ ğ’‚…ğ’Œ’ ğ’Š®ğ’‰ğ’…—

 	
ğ’„¿ğ’ˆ¾ ğ’„­ğ’•ğ’€€ğ’Œ“ ğ’…‡ ğ’Š‘ğ’ƒ»ğ’€€ğ’Œ“

40	
ğ’„¿ğ’ˆ¾ ğ’‚Šğ’Š‘ğ’‰ğ’…— ğ’„¿ğ’ˆ¾ ğ’† ğ’‰ğ’‹¾ğ’…—

 	
ğ’†¤ğ’‹¾ ğ’Š­ ğ’†· ğ’‘ğ’Œ“ğ’Š“ğ’†ª ğ’‡·ğ’Š‘ğ’†ª ğ’Œ“ğ’ˆªğ’Š

 	
ğ’‡·ğ’ˆªğ’• ğ’ˆ¬ğ’€­ğ’ˆ¾ğ’‹¾ğ’Š

 	
ğ’‡·ğ’†² ğ’„‘ğ’„–ğ’ğ’Œ‘ğ’€€ ğ’‡·ğ’…‹ğ’‰ğ’…•

 	
ğ’‰ºğ’‡»ğ’Œ‘ğ’€€ ğ’„¿ğ’ˆ¾ ğ’„‘ğ’•ğ’…— ğ’¢ğ’„¿ğ’Š‘

45	
ğ’ˆ¬ğ’†¥ ğ’„ğ’‡»ğ’ŠŒğ’†ª ğ’€­ğ’‚Š ğ’Œ‹ ğ’† ğ’´

 	
ğ’„¿ğ’ˆ¾ ğ’‰¿ğ’„¿ğ’…— ğ’‚–ğ’‡· ğ’‡ºğ’‹³ğ’…—ğ’‰¡

 	
ğ’ºğ’Œ¦ğ’† ğ’Š ğ’†³ğ’†³ğ’ˆ¨ğ’Œ ğ’‹« ğ’¢ğ’€‰ ğ’€­ğ’Œ“ğ’…†

 	
ğ’€€ğ’² ğ’‚Šğ’Š‘ğ’… ğ’€­ğ’Œ“ğ’…† ğ’Œ¨ğ’‹—ğ’º

 	
ğ’‹—ğ’ˆ«ğ’€€ğ’€€ ğ’Œ‹ğ’Œ‹ğ’•ğ’€œğ’‹¾ğ’…†ğ’‰¡ ğ’‡»ğ’Š»ğ’‰Œğ’……ğ’ˆ 

50	
ğ’€€ğ’ˆ¾ ğ’‰»ğ’‡»ğ’‡» ğ’‚ğ’Š•ğ’…

 	
ğ’…‡ ğ’‚ğ’£ğ’• ğ’‡»ğ’‰ğ’…‹ ğ’€­ğ’€

 	
ğ’Œ‰ğ’‘ ğ’Š•ğ’†— ğ’€€ğ’ˆ¾ ğ’‚ğ’£ğ’•

 	
ğ’‚ ğ’† ğ’„¿ğ’‰Œ ğ’„¿ğ’ˆ¾ ğ’‚Šğ’Š‘ğ’‰ğ’…—

 	
ğ’…†ğ’‚Ÿğ’´ ğ’¹ğ’€­ğ’‹¾ğ’€ªğ’†ªğ’Š» ğ’ˆ— ğ’†³ğ’†³

55	
ğ’¹ğ’‹›ğ’‡»ğ’ŠŒğ’†ª ğ’ˆ— ğ’Œ‰ğ’‹™

 	
ğ’Š©ğ’Šğ’‹«ğ’…ˆğ’‹«ğ’‰Œğ’……ğ’†ª

 	
ğ’„­ğ’‹¥ğ’‹¢ ğ’Š¬ğ’Šğ’€œ

 	
ğ’•ğ’ˆªğ’……ğ’‹¾ğ’‹™ğ’‰¡

 	
ğ’‡·ğ’…–ğ’ƒ»ğ’†¥ ğ’„¿ğ’ˆ¾ ğ’‰¿ğ’„¿ğ’…—
"""
    print(transliterate(example))
    #print(transliterate_bilstm(example))
    #print(transliterate_bilstm_top3(example))
    print(transliterate_hmm(example))
    print(transliterate_memm(example))
    #main()
